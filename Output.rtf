{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf400
{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c100000\c100000\c100000;\cssrgb\c0\c0\c0;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf0 \cb2 \expnd0\expndtw0\kerning0
Loading 29 samples into memory for training.\
Loading 14 samples into memory for testing.\
Loading Conv3D\
_________________________________________________________________\
Layer (type)                 Output Shape              Param #   \
=================================================================\
conv3d_1 (Conv3D)            (None, 38, 78, 78, 32)    2624      \
_________________________________________________________________\
max_pooling3d_1 (MaxPooling3 (None, 38, 39, 39, 32)    0         \
_________________________________________________________________\
conv3d_2 (Conv3D)            (None, 36, 37, 37, 64)    55360     \
_________________________________________________________________\
max_pooling3d_2 (MaxPooling3 (None, 36, 18, 18, 64)    0         \
_________________________________________________________________\
conv3d_3 (Conv3D)            (None, 34, 16, 16, 128)   221312    \
_________________________________________________________________\
conv3d_4 (Conv3D)            (None, 32, 14, 14, 128)   442496    \
_________________________________________________________________\
max_pooling3d_3 (MaxPooling3 (None, 32, 7, 7, 128)     0         \
_________________________________________________________________\
conv3d_5 (Conv3D)            (None, 31, 6, 6, 256)     262400    \
_________________________________________________________________\
conv3d_6 (Conv3D)            (None, 30, 5, 5, 256)     524544    \
_________________________________________________________________\
max_pooling3d_4 (MaxPooling3 (None, 30, 2, 2, 256)     0         \
_________________________________________________________________\
flatten_1 (Flatten)          (None, 30720)             0         \
_________________________________________________________________\
dense_1 (Dense)              (None, 1024)              31458304  \
_________________________________________________________________\
dropout_1 (Dropout)          (None, 1024)              0         \
_________________________________________________________________\
dense_2 (Dense)              (None, 1024)              1049600   \
_________________________________________________________________\
dropout_2 (Dropout)          (None, 1024)              0         \
_________________________________________________________________\
dense_3 (Dense)              (None, 5)                 5125      \
=================================================================\
Total params: 34,021,765\
Trainable params: 34,021,765\
Non-trainable params: 0\
_________________________________________________________________\
None\
Train on 29 samples, validate on 14 samples\
Epoch 1/80\
29/29 [==============================] - 102s 4s/step - loss: 1.6122 - acc: 0.2759 - val_loss: 1.6134 - val_acc: 0.1429\
Epoch 2/80\
29/29 [==============================] - 97s 3s/step - loss: 1.5947 - acc: 0.2414 - val_loss: 1.6130 - val_acc: 0.1429\
Epoch 3/80\
29/29 [==============================] - 96s 3s/step - loss: 1.6001 - acc: 0.2414 - val_loss: 1.6125 - val_acc: 0.1429\
Epoch 4/80\
29/29 [==============================] - 97s 3s/step - loss: 1.5978 - acc: 0.3448 - val_loss: 1.6118 - val_acc: 0.1429\
Epoch 5/80\
29/29 [==============================] - 97s 3s/step - loss: 1.5917 - acc: 0.3103 - val_loss: 1.6112 - val_acc: 0.1429\
Epoch 6/80\
29/29 [==============================] - 97s 3s/step - loss: 1.5735 - acc: 0.3448 - val_loss: 1.6106 - val_acc: 0.1429\
Epoch 7/80\
29/29 [==============================] - 96s 3s/step - loss: 1.5824 - acc: 0.3448 - val_loss: 1.6099 - val_acc: 0.1429\
Epoch 8/80\
29/29 [==============================] - 98s 3s/step - loss: 1.5958 - acc: 0.2414 - val_loss: 1.6090 - val_acc: 0.1429\
Epoch 9/80\
29/29 [==============================] - 103s 4s/step - loss: 1.5692 - acc: 0.3103 - val_loss: 1.6080 - val_acc: 0.1429\
Epoch 10/80\
29/29 [==============================] - 121s 4s/step - loss: 1.5708 - acc: 0.3793 - val_loss: 1.6069 - val_acc: 0.2143\
Epoch 11/80\
29/29 [==============================] - 107s 4s/step - loss: 1.5749 - acc: 0.3448 - val_loss: 1.6058 - val_acc: 0.2143\
Epoch 12/80\
29/29 [==============================] - 112s 4s/step - loss: 1.5600 - acc: 0.3793 - val_loss: 1.6047 - val_acc: 0.2857\
Epoch 13/80\
29/29 [==============================] - 116s 4s/step - loss: 1.5716 - acc: 0.2414 - val_loss: 1.6037 - val_acc: 0.2857\
Epoch 14/80\
29/29 [==============================] - 117s 4s/step - loss: 1.5648 - acc: 0.3103 - val_loss: 1.6025 - val_acc: 0.2857\
Epoch 15/80\
29/29 [==============================] - 116s 4s/step - loss: 1.5705 - acc: 0.2414 - val_loss: 1.6015 - val_acc: 0.2857\
Epoch 16/80\
29/29 [==============================] - 116s 4s/step - loss: 1.5493 - acc: 0.3793 - val_loss: 1.6004 - val_acc: 0.2857\
Epoch 17/80\
29/29 [==============================] - 114s 4s/step - loss: 1.5351 - acc: 0.4138 - val_loss: 1.5992 - val_acc: 0.2857\
Epoch 18/80\
29/29 [==============================] - 108s 4s/step - loss: 1.5371 - acc: 0.4828 - val_loss: 1.5979 - val_acc: 0.2857\
Epoch 19/80\
29/29 [==============================] - 105s 4s/step - loss: 1.5001 - acc: 0.6207 - val_loss: 1.5965 - val_acc: 0.2857\
Epoch 20/80\
29/29 [==============================] - 118s 4s/step - loss: 1.5320 - acc: 0.4828 - val_loss: 1.5949 - val_acc: 0.2857\
Epoch 21/80\
29/29 [==============================] - 105s 4s/step - loss: 1.5463 - acc: 0.3448 - val_loss: 1.5936 - val_acc: 0.2857\
Epoch 22/80\
29/29 [==============================] - 100s 3s/step - loss: 1.5062 - acc: 0.5517 - val_loss: 1.5923 - val_acc: 0.2857\
Epoch 23/80\
29/29 [==============================] - 98s 3s/step - loss: 1.5387 - acc: 0.4138 - val_loss: 1.5910 - val_acc: 0.2857\
Epoch 24/80\
29/29 [==============================] - 97s 3s/step - loss: 1.4917 - acc: 0.5172 - val_loss: 1.5894 - val_acc: 0.2857\
Epoch 25/80\
29/29 [==============================] - 98s 3s/step - loss: 1.5324 - acc: 0.3448 - val_loss: 1.5878 - val_acc: 0.2857\
Epoch 26/80\
29/29 [==============================] - 98s 3s/step - loss: 1.4842 - acc: 0.5172 - val_loss: 1.5861 - val_acc: 0.2857\
Epoch 27/80\
29/29 [==============================] - 98s 3s/step - loss: 1.4976 - acc: 0.4828 - val_loss: 1.5843 - val_acc: 0.2857\
Epoch 28/80\
29/29 [==============================] - 97s 3s/step - loss: 1.4461 - acc: 0.7586 - val_loss: 1.5824 - val_acc: 0.2857\
Epoch 29/80\
29/29 [==============================] - 98s 3s/step - loss: 1.4631 - acc: 0.5862 - val_loss: 1.5805 - val_acc: 0.2857\
Epoch 30/80\
29/29 [==============================] - 98s 3s/step - loss: 1.4988 - acc: 0.5517 - val_loss: 1.5783 - val_acc: 0.2857\
Epoch 31/80\
29/29 [==============================] - 113s 4s/step - loss: 1.4608 - acc: 0.5517 - val_loss: 1.5760 - val_acc: 0.3571\
Epoch 32/80\
29/29 [==============================] - 112s 4s/step - loss: 1.4394 - acc: 0.7241 - val_loss: 1.5734 - val_acc: 0.3571\
Epoch 33/80\
29/29 [==============================] - 110s 4s/step - loss: 1.4251 - acc: 0.6552 - val_loss: 1.5706 - val_acc: 0.3571\
Epoch 34/80\
29/29 [==============================] - 110s 4s/step - loss: 1.4225 - acc: 0.6897 - val_loss: 1.5676 - val_acc: 0.3571\
Epoch 35/80\
29/29 [==============================] - 109s 4s/step - loss: 1.4448 - acc: 0.6207 - val_loss: 1.5644 - val_acc: 0.3571\
Epoch 36/80\
29/29 [==============================] - 107s 4s/step - loss: 1.4332 - acc: 0.5517 - val_loss: 1.5611 - val_acc: 0.3571\
Epoch 37/80\
29/29 [==============================] - 111s 4s/step - loss: 1.3690 - acc: 0.7586 - val_loss: 1.5574 - val_acc: 0.3571\
Epoch 38/80\
29/29 [==============================] - 108s 4s/step - loss: 1.3691 - acc: 0.7241 - val_loss: 1.5538 - val_acc: 0.3571\
Epoch 39/80\
29/29 [==============================] - 110s 4s/step - loss: 1.3574 - acc: 0.7241 - val_loss: 1.5498 - val_acc: 0.3571\
Epoch 40/80\
29/29 [==============================] - 109s 4s/step - loss: 1.3389 - acc: 0.7931 - val_loss: 1.5457 - val_acc: 0.4286\
Epoch 41/80\
29/29 [==============================] - 108s 4s/step - loss: 1.3576 - acc: 0.7586 - val_loss: 1.5417 - val_acc: 0.5000\
Epoch 42/80\
29/29 [==============================] - 108s 4s/step - loss: 1.3142 - acc: 0.7241 - val_loss: 1.5375 - val_acc: 0.5000\
Epoch 43/80\
29/29 [==============================] - 108s 4s/step - loss: 1.3038 - acc: 0.7586 - val_loss: 1.5331 - val_acc: 0.5000\
\pard\pardeftab720\partightenfactor0
\cf0 \cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2 Epoch 44/80\
29/29 [==============================] - 107s 4s/step - loss: 1.3039 - acc: 0.7931 - val_loss: 1.5284 - val_acc: 0.5000\
Epoch 45/80\
29/29 [==============================] - 109s 4s/step - loss: 1.2848 - acc: 0.7241 - val_loss: 1.5234 - val_acc: 0.5000\
Epoch 46/80\
29/29 [==============================] - 109s 4s/step - loss: 1.2727 - acc: 0.7931 - val_loss: 1.5179 - val_acc: 0.5000\
Epoch 47/80\
29/29 [==============================] - 108s 4s/step - loss: 1.2466 - acc: 0.7931 - val_loss: 1.5115 - val_acc: 0.5000\
Epoch 48/80\
29/29 [==============================] - 109s 4s/step - loss: 1.1959 - acc: 0.8621 - val_loss: 1.5047 - val_acc: 0.5000\
Epoch 49/80\
29/29 [==============================] - 111s 4s/step - loss: 1.2049 - acc: 0.7586 - val_loss: 1.4976 - val_acc: 0.5000\
Epoch 50/80\
29/29 [==============================] - 112s 4s/step - loss: 1.1637 - acc: 0.8966 - val_loss: 1.4906 - val_acc: 0.4286\
Epoch 51/80\
29/29 [==============================] - 109s 4s/step - loss: 1.1666 - acc: 0.8966 - val_loss: 1.4838 - val_acc: 0.4286\
Epoch 52/80\
29/29 [==============================] - 110s 4s/step - loss: 1.1306 - acc: 0.8966 - val_loss: 1.4767 - val_acc: 0.4286\
Epoch 53/80\
29/29 [==============================] - 110s 4s/step - loss: 1.1116 - acc: 0.7241 - val_loss: 1.4698 - val_acc: 0.4286\
Epoch 54/80\
29/29 [==============================] - 108s 4s/step - loss: 1.1007 - acc: 0.8276 - val_loss: 1.4630 - val_acc: 0.4286\
Epoch 55/80\
29/29 [==============================] - 109s 4s/step - loss: 1.0996 - acc: 0.7931 - val_loss: 1.4568 - val_acc: 0.4286\
Epoch 56/80\
29/29 [==============================] - 109s 4s/step - loss: 1.0501 - acc: 0.7931 - val_loss: 1.4508 - val_acc: 0.5000\
Epoch 57/80\
29/29 [==============================] - 117s 4s/step - loss: 1.0648 - acc: 0.7586 - val_loss: 1.4433 - val_acc: 0.5000\
Epoch 58/80\
29/29 [==============================] - 121s 4s/step - loss: 0.9959 - acc: 0.8621 - val_loss: 1.4347 - val_acc: 0.5714\
Epoch 59/80\
29/29 [==============================] - 114s 4s/step - loss: 0.9942 - acc: 0.8276 - val_loss: 1.4236 - val_acc: 0.4286\
Epoch 60/80\
29/29 [==============================] - 112s 4s/step - loss: 0.9061 - acc: 0.8621 - val_loss: 1.4127 - val_acc: 0.3571\
Epoch 61/80\
29/29 [==============================] - 110s 4s/step - loss: 0.9305 - acc: 0.8621 - val_loss: 1.4027 - val_acc: 0.3571\
Epoch 62/80\
29/29 [==============================] - 111s 4s/step - loss: 0.9146 - acc: 0.8966 - val_loss: 1.3928 - val_acc: 0.3571\
Epoch 63/80\
29/29 [==============================] - 109s 4s/step - loss: 0.8585 - acc: 0.8621 - val_loss: 1.3837 - val_acc: 0.4286\
Epoch 64/80\
29/29 [==============================] - 115s 4s/step - loss: 0.8601 - acc: 0.8621 - val_loss: 1.3752 - val_acc: 0.5000\
Epoch 65/80\
29/29 [==============================] - 117s 4s/step - loss: 0.7814 - acc: 0.8966 - val_loss: 1.3696 - val_acc: 0.5000\
Epoch 66/80\
29/29 [==============================] - 110s 4s/step - loss: 0.8368 - acc: 0.7931 - val_loss: 1.3618 - val_acc: 0.5000\
Epoch 67/80\
29/29 [==============================] - 109s 4s/step - loss: 0.7509 - acc: 0.8621 - val_loss: 1.3529 - val_acc: 0.6429\
Epoch 68/80\
29/29 [==============================] - 108s 4s/step - loss: 0.7235 - acc: 0.9310 - val_loss: 1.3427 - val_acc: 0.5714\
Epoch 69/80\
29/29 [==============================] - 108s 4s/step - loss: 0.7256 - acc: 0.8276 - val_loss: 1.3351 - val_acc: 0.4286\
Epoch 70/80\
29/29 [==============================] - 106s 4s/step - loss: 0.6811 - acc: 0.9310 - val_loss: 1.3327 - val_acc: 0.3571\
Epoch 71/80\
29/29 [==============================] - 99s 3s/step - loss: 0.6108 - acc: 0.8966 - val_loss: 1.3280 - val_acc: 0.3571\
Epoch 72/80\
29/29 [==============================] - 100s 3s/step - loss: 0.5614 - acc: 0.9310 - val_loss: 1.3224 - val_acc: 0.3571\
Epoch 73/80\
29/29 [==============================] - 99s 3s/step - loss: 0.6292 - acc: 0.8621 - val_loss: 1.3165 - val_acc: 0.3571\
Epoch 74/80\
29/29 [==============================] - 98s 3s/step - loss: 0.5179 - acc: 0.9655 - val_loss: 1.3092 - val_acc: 0.4286\
Epoch 75/80\
29/29 [==============================] - 97s 3s/step - loss: 0.5889 - acc: 0.9310 - val_loss: 1.3042 - val_acc: 0.5000\
Epoch 76/80\
29/29 [==============================] - 98s 3s/step - loss: 0.5895 - acc: 0.8621 - val_loss: 1.2987 - val_acc: 0.4286\
Epoch 77/80\
29/29 [==============================] - 100s 3s/step - loss: 0.5723 - acc: 0.8966 - val_loss: 1.2924 - val_acc: 0.5000\
Epoch 78/80\
29/29 [==============================] - 98s 3s/step - loss: 0.4902 - acc: 0.8621 - val_loss: 1.2876 - val_acc: 0.5000\
Epoch 79/80\
29/29 [==============================] - 98s 3s/step - loss: 0.5597 - acc: 0.8621 - val_loss: 1.2900 - val_acc: 0.5000\
Epoch 80/80\
29/29 [==============================] - 99s 3s/step - loss: 0.4418 - acc: 0.8966 - val_loss: 1.2931 - val_acc: 0.5000}